hparam: {'CMC_rots': 'RY',
 'SEC_entgl': 'CNOT',
 'SEC_rots': 'RY',
 'alt': False,
 'alt_step': 10,
 'analyzer': 'kgram',
 'batch_size': 4,
 'binary': False,
 'ckpt_interval': 200,
 'debug_step': False,
 'embed_avg': 0.0,
 'embed_dim': 4,
 'embed_norm': 1,
 'embed_var': 0.2,
 'epochs': 4,
 'expname': 'kgram_YouroQ',
 'grad_dx': 0.01,
 'grad_meth': 'fd',
 'init_H': False,
 'init_H_p': True,
 'init_H_q': False,
 'inspect': False,
 'limit': -1,
 'log_interval': 50,
 'lr': 0.01,
 'min_freq': 10,
 'mnet': False,
 'model': 'YouroQ',
 'n_class': 4,
 'n_len': 8,
 'n_param': 5252,
 'n_param_psi': 276,
 'n_param_tht': 4976,
 'n_qubit': 12,
 'n_qubit_p': 4,
 'n_qubit_q': 8,
 'n_repeat': 4,
 'n_vocab': 1244,
 'n_vote': 5,
 'noise': 1e-05,
 'onehot': True,
 'optim': 'Adam',
 'out_dp': 'log\\kgram\\YouroQ',
 'pad': '\x00',
 'param_cnt': 5252,
 'proj': 'onehot',
 'seed': 10141,
 'slog_interval': 10,
 'tgt_cls': 0}
[Epoch 0/4]
>> [Step 10] loss: 0.18312461972236632, acc: 30.000%
>> [Step 20] loss: 0.17019533440470697, acc: 28.750%
>> [Step 30] loss: 0.1648937374353409, acc: 25.000%
>> [Step 40] loss: 0.16047116816043855, acc: 25.625%
>> [Step 50] loss: 0.15883005440235137, acc: 26.000%
>> [Step 50] loss: 0.15883005440235137, acc: 26.000%
>> acc: 23.750%
>> f1: [0.378, 0.119, 0.0, 0.0]
>> score: 7.455
>> better f1 0.12425 found, save ckpt
>> [Step 60] loss: 0.1487570509314537, acc: 25.000%
>> [Step 70] loss: 0.14863912537693977, acc: 26.250%
>> [Step 80] loss: 0.14776561160882315, acc: 27.500%
>> [Step 90] loss: 0.14766073189675807, acc: 26.250%
>> [Step 100] loss: 0.14802366822957994, acc: 24.500%
>> [Step 100] loss: 0.14802366822957994, acc: 24.500%
>> acc: 25.000%
>> f1: [0.0, 0.398, 0.02, 0.08]
>> score: 7.470000000000001
>> better f1 0.12450000000000001 found, save ckpt
>> [Step 110] loss: 0.14650354236364366, acc: 22.500%
>> [Step 120] loss: 0.14592185765504836, acc: 26.250%
>> [Step 130] loss: 0.14611472437779108, acc: 27.500%
>> [Step 140] loss: 0.14634421542286874, acc: 25.000%
>> [Step 150] loss: 0.14692575126886367, acc: 22.500%
>> [Step 150] loss: 0.14692575126886367, acc: 22.500%
>> acc: 27.750%
>> f1: [0.0, 0.389, 0.071, 0.34]
>> score: 12.0
>> better f1 0.2 found, save ckpt
>> [Step 160] loss: 0.14342380464076995, acc: 25.000%
>> [Step 170] loss: 0.14244247153401374, acc: 26.250%
>> [Step 180] loss: 0.14326711297035216, acc: 25.833%
>> [Step 190] loss: 0.14425745867192746, acc: 23.750%
>> [Step 200] loss: 0.14371757924556733, acc: 26.000%
>> [Step 200] loss: 0.14371757924556733, acc: 26.000%
>> acc: 24.750%
>> f1: [0.0, 0.397, 0.018, 0.038]
>> score: 6.795
>> [Step 210] loss: 0.14318399280309677, acc: 25.000%
>> [Step 220] loss: 0.14382922649383545, acc: 28.750%
>> [Step 230] loss: 0.1438868189851443, acc: 26.667%
>> [Step 240] loss: 0.14298846013844013, acc: 30.000%
>> [Step 250] loss: 0.14295098453760147, acc: 30.000%
>> [Step 250] loss: 0.14295098453760147, acc: 30.000%
>> acc: 27.500%
>> f1: [0.0, 0.33, 0.197, 0.352]
>> score: 13.185
>> better f1 0.21975 found, save ckpt
>> [Step 260] loss: 0.14737747237086296, acc: 22.500%
>> [Step 270] loss: 0.1460961852222681, acc: 21.250%
>> [Step 280] loss: 0.14532371188203494, acc: 23.333%
>> [Step 290] loss: 0.14560788739472627, acc: 20.625%
>> [Step 300] loss: 0.14485580638051032, acc: 23.500%
>> [Step 300] loss: 0.14485580638051032, acc: 23.500%
>> acc: 24.250%
>> f1: [0.0, 0.019, 0.304, 0.346]
>> score: 10.035
>> [Step 310] loss: 0.14066063463687897, acc: 35.000%
>> [Step 320] loss: 0.14161982722580432, acc: 36.250%
>> [Step 330] loss: 0.1440547081331412, acc: 28.333%
>> [Step 340] loss: 0.1438314100727439, acc: 28.125%
>> [Step 350] loss: 0.1433600340783596, acc: 29.000%
>> [Step 350] loss: 0.1433600340783596, acc: 29.000%
>> acc: 25.750%
>> f1: [0.374, 0.247, 0.0, 0.086]
>> score: 10.604999999999999
>> [Step 360] loss: 0.1440504163503647, acc: 25.000%
>> [Step 370] loss: 0.14322113394737243, acc: 31.250%
>> [Step 380] loss: 0.14321984698375065, acc: 28.333%
>> [Step 390] loss: 0.1428462028503418, acc: 25.000%
>> [Step 400] loss: 0.14292953491210938, acc: 24.000%
>> [Step 400] loss: 0.14292953491210938, acc: 24.000%
>> acc: 24.250%
>> f1: [0.082, 0.263, 0.234, 0.315]
>> score: 13.410000000000002
>> better f1 0.22350000000000003 found, save ckpt
[Epoch 1/4]
